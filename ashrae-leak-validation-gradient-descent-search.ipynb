{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Acknowledgements\n",
    "\n",
    "Original Kernel: https://www.kaggle.com/yamsam/ashrae-leak-validation-and-more/notebook#Leak-Validation-for-public-kernels(not-used-leak-data),\n",
    "\n",
    "https://www.kaggle.com/khoongweihao/ashrae-leak-validation-bruteforce-heuristic-search\n",
    "\n",
    "Additions: Added a search method based on gradient update"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# All we need is Leak Validation(LV) ?\n",
    "\n",
    "* **if you like this kernel, please upvote original kernels.**\n",
    "* update site-4 and site-15\n",
    "* Turn GPU on for better performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "this kernel is still work in progress, but i hope you can find something usefull from this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
    "execution": {
     "iopub.execute_input": "2021-10-03T23:00:13.33696Z",
     "iopub.status.busy": "2021-10-03T23:00:13.334393Z",
     "iopub.status.idle": "2021-10-03T23:00:16.195032Z",
     "shell.execute_reply": "2021-10-03T23:00:16.194158Z",
     "shell.execute_reply.started": "2021-10-03T23:00:13.336901Z"
    }
   },
   "outputs": [],
   "source": [
    "import gc\n",
    "import os\n",
    "from pathlib import Path\n",
    "import random\n",
    "import sys\n",
    "\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from IPython.core.display import display, HTML\n",
    "\n",
    "# --- plotly ---\n",
    "from plotly import tools, subplots\n",
    "import plotly.offline as py\n",
    "py.init_notebook_mode(connected=True)\n",
    "import plotly.graph_objs as go\n",
    "import plotly.express as px\n",
    "import plotly.figure_factory as ff\n",
    "\n",
    "# --- models ---\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import KFold\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "import catboost as cb\n",
    "\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-03T23:00:42.217381Z",
     "iopub.status.busy": "2021-10-03T23:00:42.217071Z",
     "iopub.status.idle": "2021-10-03T23:00:42.312875Z",
     "shell.execute_reply": "2021-10-03T23:00:42.311755Z",
     "shell.execute_reply.started": "2021-10-03T23:00:42.217329Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# Original code from https://www.kaggle.com/gemartin/load-data-reduce-memory-usage by @gemartin\n",
    "# Modified to support timestamp type, categorical type\n",
    "# Modified to add option to use float16 or not. feather format does not support float16.\n",
    "from pandas.api.types import is_datetime64_any_dtype as is_datetime\n",
    "from pandas.api.types import is_categorical_dtype\n",
    "\n",
    "def reduce_mem_usage(df, use_float16=False):\n",
    "    \"\"\" iterate through all the columns of a dataframe and modify the data type\n",
    "        to reduce memory usage.        \n",
    "    \"\"\"\n",
    "    start_mem = df.memory_usage().sum() / 1024**2\n",
    "    print('Memory usage of dataframe is {:.2f} MB'.format(start_mem))\n",
    "    \n",
    "    for col in df.columns:\n",
    "        if is_datetime(df[col]) or is_categorical_dtype(df[col]):\n",
    "            # skip datetime type or categorical type\n",
    "            continue\n",
    "        col_type = df[col].dtype\n",
    "        \n",
    "        if col_type != object:\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "            if str(col_type)[:3] == 'int':\n",
    "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                    df[col] = df[col].astype(np.int8)\n",
    "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                    df[col] = df[col].astype(np.int16)\n",
    "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                    df[col] = df[col].astype(np.int32)\n",
    "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
    "                    df[col] = df[col].astype(np.int64)  \n",
    "            else:\n",
    "                if use_float16 and c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
    "                    df[col] = df[col].astype(np.float16)\n",
    "                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "                else:\n",
    "                    df[col] = df[col].astype(np.float64)\n",
    "        else:\n",
    "            df[col] = df[col].astype('category')\n",
    "\n",
    "    end_mem = df.memory_usage().sum() / 1024**2\n",
    "    print('Memory usage after optimization is: {:.2f} MB'.format(end_mem))\n",
    "    print('Decreased by {:.1f}%'.format(100 * (start_mem - end_mem) / start_mem))\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-03T23:00:42.694124Z",
     "iopub.status.busy": "2021-10-03T23:00:42.693887Z",
     "iopub.status.idle": "2021-10-03T23:01:00.150817Z",
     "shell.execute_reply": "2021-10-03T23:01:00.149975Z",
     "shell.execute_reply.started": "2021-10-03T23:00:42.694079Z"
    }
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "root = Path('../input/ashrae-feather-format-for-fast-loading')\n",
    "\n",
    "train_df = pd.read_feather(root/'train.feather')\n",
    "test_df = pd.read_feather(root/'test.feather')\n",
    "#weather_train_df = pd.read_feather(root/'weather_train.feather')\n",
    "#weather_test_df = pd.read_feather(root/'weather_test.feather')\n",
    "building_meta_df = pd.read_feather(root/'building_metadata.feather')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-03T23:01:00.152967Z",
     "iopub.status.busy": "2021-10-03T23:01:00.152492Z",
     "iopub.status.idle": "2021-10-03T23:01:10.305352Z",
     "shell.execute_reply": "2021-10-03T23:01:10.304634Z",
     "shell.execute_reply.started": "2021-10-03T23:01:00.152917Z"
    }
   },
   "outputs": [],
   "source": [
    "# i'm now using my leak data station kernel to shortcut.\n",
    "leak_df = pd.read_feather('../input/ashrae-leak-data-station/leak.feather')\n",
    "\n",
    "leak_df.fillna(0, inplace=True)\n",
    "leak_df = leak_df[(leak_df.timestamp.dt.year > 2016) & (leak_df.timestamp.dt.year < 2019)]\n",
    "leak_df.loc[leak_df.meter_reading < 0, 'meter_reading'] = 0 # remove large negative values\n",
    "leak_df = leak_df[leak_df.building_id!=245]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-03T23:01:10.307128Z",
     "iopub.status.busy": "2021-10-03T23:01:10.306845Z",
     "iopub.status.idle": "2021-10-03T23:01:10.488925Z",
     "shell.execute_reply": "2021-10-03T23:01:10.487916Z",
     "shell.execute_reply.started": "2021-10-03T23:01:10.307083Z"
    }
   },
   "outputs": [],
   "source": [
    "leak_df.meter.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-03T23:01:21.747366Z",
     "iopub.status.busy": "2021-10-03T23:01:21.747052Z",
     "iopub.status.idle": "2021-10-03T23:01:24.352259Z",
     "shell.execute_reply": "2021-10-03T23:01:24.351494Z",
     "shell.execute_reply.started": "2021-10-03T23:01:21.747312Z"
    }
   },
   "outputs": [],
   "source": [
    "print (leak_df.duplicated().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-03T23:01:24.356182Z",
     "iopub.status.busy": "2021-10-03T23:01:24.355932Z",
     "iopub.status.idle": "2021-10-03T23:01:24.360399Z",
     "shell.execute_reply": "2021-10-03T23:01:24.359573Z",
     "shell.execute_reply.started": "2021-10-03T23:01:24.356134Z"
    }
   },
   "outputs": [],
   "source": [
    "print (len(leak_df) / len(train_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-03T23:01:28.109264Z",
     "iopub.status.busy": "2021-10-03T23:01:28.10897Z",
     "iopub.status.idle": "2021-10-03T23:01:28.819309Z",
     "shell.execute_reply": "2021-10-03T23:01:28.818518Z",
     "shell.execute_reply.started": "2021-10-03T23:01:28.109205Z"
    }
   },
   "outputs": [],
   "source": [
    "! ls ../input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-03T23:01:28.821712Z",
     "iopub.status.busy": "2021-10-03T23:01:28.821374Z",
     "iopub.status.idle": "2021-10-03T23:01:28.96365Z",
     "shell.execute_reply": "2021-10-03T23:01:28.962536Z",
     "shell.execute_reply.started": "2021-10-03T23:01:28.821666Z"
    }
   },
   "outputs": [],
   "source": [
    "del train_df\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Leak Validation for public kernels(not used leak data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-03T23:01:30.195323Z",
     "iopub.status.busy": "2021-10-03T23:01:30.194997Z",
     "iopub.status.idle": "2021-10-03T23:02:31.026011Z",
     "shell.execute_reply": "2021-10-03T23:02:31.025283Z",
     "shell.execute_reply.started": "2021-10-03T23:01:30.195268Z"
    }
   },
   "outputs": [],
   "source": [
    "sample_submission1 = pd.read_csv('../input/ashrae-kfold-lightgbm-without-leak-1-08/submission.csv', index_col=0)\n",
    "sample_submission2 = pd.read_csv('../input/ashrae-half-and-half/submission.csv', index_col=0)\n",
    "sample_submission3 = pd.read_csv('../input/ashrae-highway-kernel-route4/submission.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-03T23:02:31.027941Z",
     "iopub.status.busy": "2021-10-03T23:02:31.027677Z",
     "iopub.status.idle": "2021-10-03T23:02:36.872428Z",
     "shell.execute_reply": "2021-10-03T23:02:36.871743Z",
     "shell.execute_reply.started": "2021-10-03T23:02:31.027896Z"
    }
   },
   "outputs": [],
   "source": [
    "test_df['pred1'] = sample_submission1.meter_reading\n",
    "test_df['pred2'] = sample_submission2.meter_reading\n",
    "test_df['pred3'] = sample_submission3.meter_reading\n",
    "\n",
    "test_df.loc[test_df.pred3<0, 'pred3'] = 0 \n",
    "\n",
    "del  sample_submission1,  sample_submission2,  sample_submission3\n",
    "gc.collect()\n",
    "\n",
    "test_df = reduce_mem_usage(test_df)\n",
    "leak_df = reduce_mem_usage(leak_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-03T23:02:36.874541Z",
     "iopub.status.busy": "2021-10-03T23:02:36.873935Z",
     "iopub.status.idle": "2021-10-03T23:03:04.496777Z",
     "shell.execute_reply": "2021-10-03T23:03:04.49589Z",
     "shell.execute_reply.started": "2021-10-03T23:02:36.874224Z"
    }
   },
   "outputs": [],
   "source": [
    "leak_df = leak_df.merge(test_df[['building_id', 'meter', 'timestamp', 'pred1', 'pred2', 'pred3', 'row_id']], left_on = ['building_id', 'meter', 'timestamp'], right_on = ['building_id', 'meter', 'timestamp'], how = \"left\")\n",
    "leak_df = leak_df.merge(building_meta_df[['building_id', 'site_id']], on='building_id', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-03T23:03:04.498376Z",
     "iopub.status.busy": "2021-10-03T23:03:04.498078Z",
     "iopub.status.idle": "2021-10-03T23:03:04.794766Z",
     "shell.execute_reply": "2021-10-03T23:03:04.793972Z",
     "shell.execute_reply.started": "2021-10-03T23:03:04.498332Z"
    }
   },
   "outputs": [],
   "source": [
    "leak_df['pred1_l1p'] = np.log1p(leak_df.pred1)\n",
    "leak_df['pred2_l1p'] = np.log1p(leak_df.pred2)\n",
    "leak_df['pred3_l1p'] = np.log1p(leak_df.pred3)\n",
    "leak_df['meter_reading_l1p'] = np.log1p(leak_df.meter_reading)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-03T23:03:04.79734Z",
     "iopub.status.busy": "2021-10-03T23:03:04.796891Z",
     "iopub.status.idle": "2021-10-03T23:03:04.82289Z",
     "shell.execute_reply": "2021-10-03T23:03:04.821888Z",
     "shell.execute_reply.started": "2021-10-03T23:03:04.797147Z"
    }
   },
   "outputs": [],
   "source": [
    "leak_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-03T23:03:04.824912Z",
     "iopub.status.busy": "2021-10-03T23:03:04.824492Z",
     "iopub.status.idle": "2021-10-03T23:03:05.420784Z",
     "shell.execute_reply": "2021-10-03T23:03:05.419652Z",
     "shell.execute_reply.started": "2021-10-03T23:03:04.824739Z"
    }
   },
   "outputs": [],
   "source": [
    "leak_df[leak_df.pred1_l1p.isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-03T23:03:09.350437Z",
     "iopub.status.busy": "2021-10-03T23:03:09.349942Z",
     "iopub.status.idle": "2021-10-03T23:03:19.88989Z",
     "shell.execute_reply": "2021-10-03T23:03:19.888656Z",
     "shell.execute_reply.started": "2021-10-03T23:03:09.350372Z"
    }
   },
   "outputs": [],
   "source": [
    "#ashrae-kfold-lightgbm-without-leak-1-08\n",
    "sns.distplot(leak_df.pred1_l1p)\n",
    "sns.distplot(leak_df.meter_reading_l1p)\n",
    "\n",
    "leak_score = np.sqrt(mean_squared_error(leak_df.pred1_l1p, leak_df.meter_reading_l1p))\n",
    "print ('score1=', leak_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-03T23:03:19.892711Z",
     "iopub.status.busy": "2021-10-03T23:03:19.892154Z",
     "iopub.status.idle": "2021-10-03T23:03:30.549882Z",
     "shell.execute_reply": "2021-10-03T23:03:30.54925Z",
     "shell.execute_reply.started": "2021-10-03T23:03:19.892474Z"
    }
   },
   "outputs": [],
   "source": [
    "#ashrae-half-and-half\n",
    "sns.distplot(leak_df.pred2_l1p)\n",
    "sns.distplot(leak_df.meter_reading_l1p)\n",
    "\n",
    "leak_score = np.sqrt(mean_squared_error(leak_df.pred2_l1p, leak_df.meter_reading_l1p))\n",
    "print ('score2=', leak_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-03T23:03:30.551683Z",
     "iopub.status.busy": "2021-10-03T23:03:30.551378Z",
     "iopub.status.idle": "2021-10-03T23:03:40.639393Z",
     "shell.execute_reply": "2021-10-03T23:03:40.638666Z",
     "shell.execute_reply.started": "2021-10-03T23:03:30.551635Z"
    }
   },
   "outputs": [],
   "source": [
    "# meter split based\n",
    "sns.distplot(leak_df.pred3_l1p)\n",
    "sns.distplot(leak_df.meter_reading_l1p)\n",
    "\n",
    "leak_score = np.sqrt(mean_squared_error(leak_df.pred3_l1p, leak_df.meter_reading_l1p))\n",
    "print ('score3=', leak_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-03T23:03:40.641422Z",
     "iopub.status.busy": "2021-10-03T23:03:40.640959Z",
     "iopub.status.idle": "2021-10-03T23:03:40.645795Z",
     "shell.execute_reply": "2021-10-03T23:03:40.644771Z",
     "shell.execute_reply.started": "2021-10-03T23:03:40.641229Z"
    }
   },
   "outputs": [],
   "source": [
    "# ashrae-kfold-lightgbm-without-leak-1-08 looks best"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Leak Validation for Blending"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A one idea how we can use LV usefull is blending. We probably can find best blending method without LB probing and it's means we can save our submission."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-03T23:03:40.648547Z",
     "iopub.status.busy": "2021-10-03T23:03:40.648063Z",
     "iopub.status.idle": "2021-10-03T23:03:51.362802Z",
     "shell.execute_reply": "2021-10-03T23:03:51.361989Z",
     "shell.execute_reply.started": "2021-10-03T23:03:40.648354Z"
    }
   },
   "outputs": [],
   "source": [
    "leak_df['mean_pred'] = np.mean(leak_df[['pred1', 'pred2', 'pred3']].values, axis=1)\n",
    "leak_df['mean_pred_l1p'] = np.log1p(leak_df.mean_pred)\n",
    "leak_score = np.sqrt(mean_squared_error(leak_df.mean_pred_l1p, leak_df.meter_reading_l1p))\n",
    "\n",
    "\n",
    "sns.distplot(leak_df.mean_pred_l1p)\n",
    "sns.distplot(leak_df.meter_reading_l1p)\n",
    "\n",
    "print ('mean score=', leak_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "leak_df['median_pred'] = np.median(leak_df[['pred1', 'pred2', 'pred3']].values, axis=1)\n",
    "leak_df['median_pred_l1p'] = np.log1p(leak_df.median_pred)\n",
    "leak_score = np.sqrt(mean_squared_error(leak_df.median_pred_l1p, leak_df.meter_reading_l1p))\n",
    "\n",
    "sns.distplot(leak_df.median_pred_l1p)\n",
    "sns.distplot(leak_df.meter_reading_l1p)\n",
    "\n",
    "print ('meadian score=', leak_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ummm... it looks mean blending is beter than median blending"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Find Best Weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 10\n",
    "scores = np.zeros(N,)\n",
    "for i in range(N):\n",
    "    p = i * 1./N\n",
    "    v = p * leak_df['pred1'].values + (1.-p) * leak_df ['pred3'].values\n",
    "    vl1p = np.log1p(v)\n",
    "    scores[i] = np.sqrt(mean_squared_error(vl1p, leak_df.meter_reading_l1p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_weight = np.argmin(scores) *  1./N\n",
    "print (scores.min(), best_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# and more\n",
    "scores = np.zeros(N,)\n",
    "for i in range(N):\n",
    "    p = i * 1./N\n",
    "    v =  p * (best_weight * leak_df['pred1'].values + (1.-best_weight) * leak_df ['pred3'].values) + (1.-p) * leak_df ['pred2'].values\n",
    "    vl1p = np.log1p(v)\n",
    "    scores[i] = np.sqrt(mean_squared_error(vl1p, leak_df.meter_reading_l1p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_weight2 = np.argmin(scores) *  1./N\n",
    "print (scores.min(), best_weight2)\n",
    "# its seams better than simple mean 0.92079717"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combination Search by using gradient descent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$x$ \\- input \n",
    "\n",
    "$y$ \\- target\n",
    "\n",
    "$w$ \\- weights\n",
    "\n",
    "Let $f(x)=w^\\top x$, we want to minimize\n",
    "\n",
    "$$L(x,y)=(\\log(f(x)+1)-\\log(y+1))^2$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data\n",
    "\n",
    "X_train = np.array([leak_df['pred1'].values,leak_df['pred2'].values, leak_df['pred3'].values]).T\n",
    "y_train = leak_df.meter_reading_l1p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-output": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "weights = tf.Variable([[0.3],[0.3],[0.3]])\n",
    "steps = 1000\n",
    "\n",
    "lr = 0.1\n",
    "\n",
    "opt = tf.optimizers.SGD(lr)\n",
    "\n",
    "#Speed up the train step by precompiling\n",
    "@tf.function()\n",
    "def train_step(opt):\n",
    "    with tf.GradientTape() as tape:\n",
    "        y  = tf.matmul(X_train, weights)[:,0]\n",
    "        loss = tf.reduce_mean((tf.math.log1p(y) - y_train) ** 2)\n",
    "    grads = tape.gradient(loss, weights)\n",
    "    opt.apply_gradients([(grads, weights)])\n",
    "    \n",
    "    return loss\n",
    "\n",
    "prev_loss = 9999\n",
    "for i in range(steps):\n",
    "    loss = train_step(opt)\n",
    "    if loss > prev_loss:\n",
    "        lr /= 2\n",
    "        opt.lr = lr\n",
    "        \n",
    "    prev_loss = loss\n",
    "    print(f'step: {i} {loss.numpy()}')   \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MSE\n",
    "np.sqrt(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission = pd.read_feather(os.path.join(root, 'sample_submission.feather'))\n",
    "\n",
    "ws = weights.numpy()\n",
    "\n",
    "w1 = ws[0,0]\n",
    "w2 = ws[1,0]\n",
    "w3 = ws[2,0]\n",
    "print(\"The weights are: w1=\" + str(w1) + \", w2=\" + str(w2) + \", w3=\" + str(w3))\n",
    "\n",
    "sample_submission['meter_reading'] = w1 * test_df.pred1 +  w2 * test_df.pred2  + w3 * test_df.pred3\n",
    "sample_submission.loc[sample_submission.meter_reading < 0, 'meter_reading'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "leak_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(np.log1p(sample_submission.meter_reading))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "leak_df = leak_df[['meter_reading', 'row_id']].set_index('row_id').dropna()\n",
    "sample_submission.loc[leak_df.index, 'meter_reading'] = leak_df['meter_reading']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(np.log1p(sample_submission.meter_reading))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission.to_csv('submission.csv', index=False, float_format='%.4f')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Future Work\n",
    "\n",
    "- Do cross-validation on leak data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(\"/kaggle/working\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import FileLink\n",
    "FileLink(r'submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
